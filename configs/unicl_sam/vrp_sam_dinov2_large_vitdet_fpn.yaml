model:
  dinov2_config:
    type: "ckpts/dinov2/large"
  fpn_config:
    out_channels: 512
    refine_level: 1
    multi_scale_fusion: 'bfp'
    norm_type: 'LN'
  gnn_config:
    type: 'deepcut' # 'g-unet' deepcut kmeans
    graph_type: 'part'
    kmeans: false
    cluster_loss: false
    kl_loss: false
    with_graph_pe: false
    with_g_attn: false
    depth: 3
    cut: 0
    alpha: 3
    K: 10
  qformer_config:
    add_cross_attn: true
    num_hidden_layers: 2
    hidden_size: 256
    layer_norm_eps: 1e-12
    hidden_dropout_prob: 0.1
    num_attention_heads: 16
    encoder_hidden_size: 512
    attention_probs_dropout_prob: 0.1
    max_position_embeddings: 512
    chunk_size_feed_forward: 0
    num_query_tokens: 50
    with_bg_query: true
    num_bg_query_tokens: 50
    intermediate_size: 3072
    hidden_act: "gelu"
  sam_config:
    type: vit_h
    ckpt: "ckpts/sam/sam_vit_h_4b8939.pth"
    train_mask_decoder: false
  with_simple_fpn: true
  feat_interpolate: false
  with_mask: true
  with_mask_pooling: true
  no_augment: false
  with_mlp_reweight: false
loss:
  dice: 5
  ce: 20
  cls: 5
  # focal: 10
  # iou: 10